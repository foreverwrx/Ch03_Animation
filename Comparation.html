<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Attention Mechanisms Animation</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.4.2/p5.min.js"></script>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            flex-direction: column;
            align-items: center;
            background-color: #f0f0f0;
            margin: 0;
            padding: 20px;
        }
        canvas {
            border: 1px solid #000;
            margin-top: 20px;
        }
        #controls {
            margin-bottom: 20px;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            font-size: 16px;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #ddd;
        }
        #output {
            margin-top: 20px;
            font-size: 18px;
            text-align: center;
        }
        .mode-highlight {
            font-weight: bold;
            color: #007bff;
        }
        .generation-explanation {
            font-size: 14px;
            color: #555;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <div id="controls">
        <button onclick="setMode('simple')">Simple Self-Attention</button>
        <button onclick="setMode('weighted')">Weighted Self-Attention</button>
        <button onclick="setMode('causal')">Causal Self-Attention</button>
        <button onclick="setMode('multihead')">Multi-Head Attention</button>
    </div>
    <div id="output"></div>
    <script>
        let mode = 'simple';
        const inputSentence = "The old castle stood silently on the hill";
        const tokens = inputSentence.split(' ');
        const tokenCount = tokens.length;
        const outputSentences = {
            simple: "The hill echoed with silent memories.",
            weighted: "The castle's walls hid ancient secrets.",
            causal: "Its stones told tales of old.",
            multihead: "Its ancient towers whispered forgotten legends."
        };
        const generationExplanations = {
            simple: "Generated by equally weighting all input tokens, leading to a broad but unfocused output.",
            weighted: "Generated by prioritizing 'castle' and 'hill' with higher weights, focusing on key context.",
            causal: "Generated by attending only to previous tokens, building the output sequentially.",
            multihead: "Generated by combining multiple attention patterns, capturing diverse relationships."
        };
        let attentionWeights = [];
        let targetWeights = [];
        let currentWeights = [];
        let outputIndex = 0;
        let animationProgress = 0;
        const animationDuration = 30;

        function setMode(newMode) {
            mode = newMode;
            outputIndex = 0;
            animationProgress = 0;
            setupAttentionWeights();
            updateOutputText();
        }

        function setupAttentionWeights() {
            targetWeights = [];
            currentWeights = [];
            if (mode === 'simple') {
                const weight = 1 / tokenCount;
                for (let i = 0; i < tokenCount; i++) {
                    targetWeights[i] = Array(tokenCount).fill(weight);
                    currentWeights[i] = Array(tokenCount).fill(0);
                }
            } else if (mode === 'weighted') {
                for (let i = 0; i < tokenCount; i++) {
                    targetWeights[i] = Array(tokenCount).fill(0.1);
                    if (tokens[i] === 'castle' || tokens[i] === 'hill') {
                        targetWeights[i][tokens.indexOf('castle')] = 0.4;
                        targetWeights[i][tokens.indexOf('hill')] = 0.3;
                    } else {
                        targetWeights[i][i] = 0.3;
                    }
                    const sum = targetWeights[i].reduce((a, b) => a + b, 0);
                    targetWeights[i] = targetWeights[i].map(w => w / sum);
                    currentWeights[i] = Array(tokenCount).fill(0);
                }
            } else if (mode === 'causal') {
                for (let i = 0; i < tokenCount; i++) {
                    targetWeights[i] = Array(tokenCount).fill(0);
                    for (let j = 0; j <= i; j++) {
                        targetWeights[i][j] = 1 / (i + 1);
                    }
                    currentWeights[i] = Array(tokenCount).fill(0);
                }
            } else if (mode === 'multihead') {
                for (let i = 0; i < tokenCount; i++) {
                    const head1 = Array(tokenCount).fill(0.1);
                    if (tokens[i] === 'castle' || tokens[i] === 'hill') {
                        head1[tokens.indexOf('castle')] = 0.4;
                        head1[tokens.indexOf('hill')] = 0.3;
                    }
                    const head2 = Array(tokenCount).fill(0);
                    if (i > 0) head2[i - 1] = 0.5;
                    if (i < tokenCount - 1) head2[i + 1] = 0.5;
                    const sum1 = head1.reduce((a, b) => a + b, 0);
                    const sum2 = head2.reduce((a, b) => a + b, 0);
                    targetWeights[i] = head1.map((w, idx) => (w / sum1 + (head2[idx] / (sum2 || 1))) / 2);
                    currentWeights[i] = Array(tokenCount).fill(0);
                }
            }
        }

        function updateOutputText() {
            const outputTokens = outputSentences[mode].split(' ');
            document.getElementById('output').innerHTML = `Mode: <span class="mode-highlight">${mode.charAt(0).toUpperCase() + mode.slice(1)} Self-Attention</span><br>Input: ${inputSentence}<br>Output: ${outputTokens.slice(0, outputIndex + 1).join(' ')}<br><span class="generation-explanation">${generationExplanations[mode]}</span>`;
        }

        function setup() {
            createCanvas(800, 500);
            textAlign(CENTER, CENTER);
            textSize(16);
            setupAttentionWeights();
            frameRate(60);
            updateOutputText();
        }

        function draw() {
            background(255);
            const radius = 30;
            const spacing = 100;
            const startX = (width - (tokenCount - 1) * spacing) / 2;
            const inputY = 100;
            const outputY = 200;
            const outputTokens = outputSentences[mode].split(' ');

            // Smoothly interpolate attention weights
            if (animationProgress < animationDuration) {
                animationProgress++;
                const t = animationProgress / animationDuration;
                for (let i = 0; i < tokenCount; i++) {
                    for (let j = 0; j < tokenCount; j++) {
                        currentWeights[i][j] = lerp(currentWeights[i][j] || 0, targetWeights[i][j] || 0, t);
                    }
                }
            }

            // Draw attention lines
            for (let i = 0; i < tokenCount; i++) {
                for (let j = 0; j < tokenCount; j++) {
                    if (currentWeights[i][j] > 0) {
                        stroke(0, 0, 255, currentWeights[i][j] * 255);
                        strokeWeight(currentWeights[i][j] * 10);
                        line(startX + i * spacing, inputY, startX + j * spacing, inputY);
                    }
                }
            }

            // Draw input tokens with stroke weight based on attention
            for (let i = 0; i < tokenCount; i++) {
                fill(200);
                if (mode === 'causal' && i < outputIndex) fill(150, 150, 255);
                // Set stroke weight based on attention for current output token
                if (outputIndex < outputTokens.length && animationProgress >= animationDuration) {
                    stroke(0, 0, 255);
                    strokeWeight(currentWeights[outputIndex % tokenCount][i] * 10);
                } else {
                    stroke(0);
                    strokeWeight(1);
                }
                ellipse(startX + i * spacing, inputY, radius * 2);
                fill(0);
                noStroke();
                text(tokens[i], startX + i * spacing, inputY);
            }

            // Draw output tokens
            for (let i = 0; i <= outputIndex && i < outputTokens.length; i++) {
                fill(150, 255, 150);
                stroke(0);
                strokeWeight(1);
                ellipse(startX + i * spacing, outputY, radius * 2);
                fill(0);
                noStroke();
                text(outputTokens[i], startX + i * spacing, outputY);
            }

            // Update output
            if (animationProgress >= animationDuration && outputIndex < outputTokens.length) {
                outputIndex++;
                animationProgress = 0;
                updateOutputText();
            }

            // Draw description table
            textSize(12);
            fill(0);
            textAlign(LEFT, TOP);
            const descY = 300;
            text('Capabilities:', 50, descY);
            text('Use Cases:', 300, descY);
            text('Limitations:', 550, descY);
            textAlign(CENTER, TOP);
            let capabilities, useCases, limitations;
            if (mode === 'simple') {
                capabilities = 'Aggregates context from all tokens equally.';
                useCases = 'Basic context modeling in small models.';
                limitations = 'Lacks focus on relevant tokens.';
            } else if (mode === 'weighted') {
                capabilities = 'Prioritizes relevant tokens via learned weights.';
                useCases = 'Improved context in tasks like sentiment analysis.';
                limitations = 'Fixed weights may miss dynamic context.';
            } else if (mode === 'causal') {
                capabilities = 'Attends only to previous tokens for sequential processing.';
                useCases = 'Text generation, language modeling.';
                limitations = 'Cannot use future context.';
            } else if (mode === 'multihead') {
                capabilities = 'Captures diverse relationships via multiple heads.';
                useCases = 'Complex tasks like translation, summarization.';
                limitations = 'Higher computational cost.';
            }
            text(capabilities, 50, descY + 20, 200);
            text(useCases, 300, descY + 20, 200);
            text(limitations, 550, descY + 20, 200);
        }
    </script>
</body>
</html>